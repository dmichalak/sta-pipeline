import subprocess
from pathlib import Path

import pandas as pd
import starfile
import mrcfile
from skimage.feature import peak_local_max

def get_peak_coordinates(
    segment_map: Path,
    min_distance: int,
    threshold_abs: float,
    threshold_rel: float,
    border_size: int
) -> pd.DataFrame:
    """Get the coordinates of the peaks in a segment map. If both threshold_abs and threshold_rel are provided, the maximum of the two is chosen as the minimum intensity threshold of peaks."""

    peaks = peak_local_max(
        mrcfile.read(segment_map),
        min_distance=min_distance,
        threshold_abs=threshold_abs,
        threshold_rel=threshold_rel,
        exclude_border=border_size,
    )

    peaks_df = pd.DataFrame(peaks, columns=["rlnCoordinateZ", "rlnCoordinateY", "rlnCoordinateX"])

    return peaks_df


def peaks_to_star(
    peaks_dataframe: pd.DataFrame,
    output_star: Path,
    tomo_bin_factor: int,
) -> None:
    """Convert a DataFrame of peak coordinates to a star file. Random angles are assigned to the peaks."""

    output_star = Path(output_star).absolute()

    rln_coordinates = ["rlnCoordinateZ", "rlnCoordinateY", "rlnCoordinateX"]
    rln_angles = ["rlnAngleRot", "rlnAngleTilt", "rlnAnglePsi"]
    optics_columns = ["rlnOpticsGroup", "rlnOpticsGroupName", "rlnVoltage", "rlnSphericalAberration", "rlnTomoTiltSeriesPixelSize"]
    optics_values = [1, "opticsGroup1", 300, 2.7, 1.0825]
    peaks_dataframe.rename(
        columns={"x": "rlnCoordinateX", "y": "rlnCoordinateY", "z": "rlnCoordinateZ"},
        inplace=True,
    )
    unbinned_peaks_dataframe = {}
    unbinned_peaks_dataframe["optics"] = pd.DataFrame(columns=optics_columns)
    unbinned_peaks_dataframe["optics"].loc[0] = optics_values

    unbinned_peaks_dataframe["particles"][rln_coordinates] = (
        peaks_dataframe[rln_coordinates] * tomo_bin_factor
    )

    for angle in rln_angles:
        random_angles = np.random.randint(
            0, 179, size=len(unbinned_peaks_dataframe.index)
        )
        unbinned_peaks_dataframe["particles"][angle] = random_angles
    # if rlnTomoName is a column in peaks_dataframe, move it to the last column index
    if "rlnTomoName" in peaks_dataframe.columns:
        unbinned_peaks_dataframe["particles"]["rlnTomoName"] = peaks_dataframe["rlnTomoName"]
        unbinned_peaks_dataframe["particles"] = unbinned_peaks_dataframe["particles"][
            [
                col
                for col in unbinned_peaks_dataframe["particles"].columns
                if col != "rlnTomoName"
            ]
            + ["rlnTomoName"]
        ]
    unbinned_peaks_dataframe["particles"]["rlnOpticsGroup"] = 1
    unbinned_peaks_dataframe["particles"]["rlnOriginXAngst"] = 0.0
    unbinned_peaks_dataframe["particles"]["rlnOriginYAngst"] = 0.0
    unbinned_peaks_dataframe["particles"]["rlnOriginZAngst"] = 0.0

    starfile.write(unbinned_peaks_dataframe, output_star, overwrite=True)


def eman2_extract(
    segmentation_directory: Path,
    neural_network: Path,
    tomo_bin_factor: int,
    min_distance: int,
    border_size: int,
    rel_threshold: float,
    abs_threshold: float,
    concatenate_star_files: bool,
) -> None:
    """Extract peaks from segmentation maps and save to a star file per tomogram. If concatenate_star_files is True, all star files are concatenated into one star file.

    Args:
        segmentation_directory (Path): Path to the directory containing the segmentation maps.
        neural_network (Path): Path to the neural network used for segmentation.
        tomo_bin_factor (int): Binning factor of the tomograms.
        min_distance (int): Minimum distance between peaks.
        border_size (int): Exclude peaks within this distance from the border of the segmentation map.
        rel_threshold (float): Relative threshold for peak detection (0.0 to 1.0).
        abs_threshold (float): Absolute threshold for peak detection.
        concatenate_star_files (bool): If True, concatenate all star files into one star file.

    Returns:
        None
"""

    segmentation_directory = Path(segmentation_directory).absolute()
    neural_network = Path(neural_network).absolute()
    segment_str = neural_network.stem.split("__")[1]

    peaks_list = []
    ts_dict = {}
    # Convert segmentation maps from .hdf to .mrc
    for hdf in sorted(segmentation_directory.glob("*.hdf")):
        if not hdf.with_suffix(".mrc").exists():
            print(f"Converting {hdf.name} to .mrc...")
            command = [
                "e2proc3d.py",
                str(hdf),
                str(hdf.with_suffix(".mrc")),
            ]
            subprocess.run(command)
        # add ts info to dict
        ts_name = hdf.stem
        ts_dict[ts_name]["tomo_path"] = hdf.with_suffix(".mrc").absolute()

        segment_path = segmentation_directory / f"{ts_name}_{segment_str}.hdf"

        if not segment_path.with_suffix(".mrc").exists():
            print(f"Converting {segment_path.name} to .mrc...")
            command = [
                "e2proc3d.py",
                str(segment_path),
                str(segment_path.with_suffix(".mrc")),
            ]
            subprocess.run(command)
        # add ts info to dict
        ts_dict[ts_name]["segment_path"] = segment_path.with_suffix(".mrc").absolute()

    # Extract peaks from segmentation maps and save to a star file per tomogram
    for ts_name in ts_dict.keys():
        print(f"Loading {ts_name} data...")
        #tomogram_mrc = mrcfile.read(ts_dict[ts_name]["tomo_path"])
        segment_mrc = mrcfile.read(ts_dict[ts_name]["segment_path"])
        starfile_name = f"{segment_mrc.stem}_abs{abs_threshold}rel{rel_threshold}.star"
        if (segmentation_directory / starfile_name).exists():
            print(f"Found {starfile_name}, skipping...")
            continue
        print(f"Extracting peaks from {ts_name}...")
        map_peaks_df = get_peak_coordinates(
            segment_mrc,
            int(min_distance),
            float(rel_threshold),
            float(abs_threshold),
            int(border_size),
        )
        print("Found", len(map_peaks_df.index), "peaks.")
        print(f"Saving peaks to {starfile_name}...")
        peaks_to_star(
            map_peaks_df,
            segmentation_directory / f"{starfile_name}",
            tomo_bin_factor=tomo_bin_factor,
            )
        peaks_list.append(map_peaks_df)

    # Concatenate all star files into one star file
    if concatenate_star_files:
        print("Concatenating all star files...")
        starfile_name = f"particles_abs{abs_threshold}rel{rel_threshold}.star"
        all_peaks = pd.concat(peaks_list, axis=0, ignore_index=True)
        peaks_to_star(
            all_peaks,
            segmentation_directory / starfile_name,
            tomo_bin_factor=tomo_bin_factor,
        )
        print(f"Saved concatenated star file to {segmentation_directory / starfile_name}.")

    print("Done!")

if __name__ == "__main__":

    segmentation_directory = Path(...).absolute()
    neural_network = Path(...).absolute()
    tomo_bin_factor = 10
    min_distance = 10 # px
    border_size = 10    # px
    rel_threshold = 0.1 # 
    abs_threshold = 0.1
    concatenate_star_files = True

    eman2_extract(
        segmentation_directory,
        neural_network,
        tomo_bin_factor,
        min_distance,
        border_size,
        rel_threshold,
        abs_threshold,
        concatenate_star_files,
    )